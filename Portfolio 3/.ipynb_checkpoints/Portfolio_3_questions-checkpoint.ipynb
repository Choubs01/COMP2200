{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z88FfJc9lA_T",
   "metadata": {
    "id": "Z88FfJc9lA_T"
   },
   "source": [
    "## Analysis of an E-commerce Dataset Part 3 (s2 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoq0NwA9lA_V",
   "metadata": {
    "id": "hoq0NwA9lA_V"
   },
   "source": [
    "\n",
    "In this Portfolio task, you will continue working with the dataset you have used in portfolio 2. But the difference is that the ratings have been converted to like (with score 1) and dislike (with score 0). Your task is to train classification models such as KNN to predict whether a user like or dislike an item.  \n",
    "\n",
    "\n",
    "The header of the csv file is shown below. \n",
    "\n",
    "| userId | timestamp | review | item | helpfulness | gender | category | item_id | item_price | user_city | rating |\n",
    "    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n",
    "    \n",
    "Your high level goal in this notebook is to try to build and evaluate predictive models for 'rating' from other available features - predict the value of the like (corresponding to rating 1) and dislike (corresponding to rating 0) in the data from some of the other fields. More specifically, you need to complete the following major steps: \n",
    "1) Explore the data. Clean the data if necessary. For example, remove abnormal instanaces and replace missing values.\n",
    "2) Convert object features into digit features by using an encoder\n",
    "3) Study the correlation between these features. \n",
    "4) Split the dataset and train a logistic regression model to predict 'rating' based on other features. Evaluate the accuracy of your model.\n",
    "5) Split the dataset and train a KNN model to predict 'rating' based on other features. You can set K with an ad-hoc manner in this step. Evaluate the accuracy of your model.\n",
    "6) Tune the hyper-parameter K in KNN to see how it influences the prediction performance\n",
    "\n",
    "Note 1: We did not provide any description of each step in the notebook. You should learn how to properly comment your notebook by yourself to make your notebook file readable. \n",
    "\n",
    "Note 2: you are not being evaluated on the ___accuracy___ of the model but on the ___process___ that you use to generate it. Please use both ___Logistic Regression model___ and ___KNN model___ for solving this classification problem. Accordingly, discuss the performance of these two methods.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c0dd4-7952-4eef-83b5-2346db1fc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42ab04-345f-4709-848a-dc1c4256d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Explore the data. Clean the data if necessary. For example, remove abnormal instanaces and replace missing values.\n",
    "data = pd.read_csv(\"portfolio_3.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e6665-caeb-48c1-863f-4a21760fd405",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32d920-0c5f-4bb4-bedb-35ca5a624526",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa3c29-e205-429c-927f-812de6fd31f7",
   "metadata": {},
   "source": [
    "We see that the data is clean already and we can move on to next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908606f-50ba-4dd2-8abf-152bd777189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Convert object features into digit features by using an encoder\n",
    "\n",
    "encoded_data = data\n",
    "# Encode non-numeric columns\n",
    "columns_to_encode = ['review', 'item', 'gender', 'category']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each column\n",
    "for col in columns_to_encode:\n",
    "    encoded_data[col] = label_encoder.fit_transform(encoded_data[col])\n",
    "\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ec41e-8e77-4962-a9c9-d66e6e118535",
   "metadata": {},
   "source": [
    "We have successfuly encoded all object feature columns into digit features. We can move on to the next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8ecb5-30d6-40c2-8b58-891414e7ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Study the correlation between these features. \n",
    "\n",
    "correlation_matrix = encoded_data.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8830d-c9bc-4ebc-9c64-39df4e770485",
   "metadata": {},
   "source": [
    "It is difficult to infer data from all these numbers. It'll be much easier to find strong correlations using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e11643-e906-4b1c-b7e7-e5a91f6e6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921856c9-d12b-49ce-ac45-c87c0e188718",
   "metadata": {},
   "source": [
    "The heatmap shows that overall, the correlation between variables isn't very high. There is a 1 to 1 correlation between item and item_id, however this is to be expected. The correlations of note are:\n",
    "- item and review: 0.16 (and by extension item_id and review)\n",
    "- helpfulness and userId: -0.17\n",
    "- rating and category: -0.14\n",
    "- category and item_price: -0.12\n",
    "\n",
    "Looking at rating specifically, the most significant correlated feature is category with -0.14, followed by userId with 0.07, and item/item_id with 0.06.\n",
    "\n",
    "Nonetheless, overall these are weak correlations. The rest of the correlations are negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c15ed1-1117-44ba-bca5-9bdc42f74754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Split the dataset and train a logistic regression model to predict 'rating' based on other features. Evaluate the accuracy of your model.\n",
    "#Split the dataset on rating\n",
    "X = encoded_data.drop('rating', axis=1)\n",
    "y = encoded_data['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Train logistic model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate model\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8cb55-ff40-42f2-b63e-345f1b536c97",
   "metadata": {},
   "source": [
    "We can see that upon training the logistic model, it's accuracy is about 64%. While this is better than a coin toss, ultimately it is too low to be considered really useful. Overall, with a logistic model, predicting rating based on all the other columns in the dataset isn't very effective. Let's try a different combination of features to see if they yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddfee6-7497-4fc3-adad-b5033d89ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Split the dataset and train a logistic regression model to predict 'rating' based on other features. Evaluate the accuracy of your model.\n",
    "#Split the dataset on rating\n",
    "X_1 = encoded_data[['category']]\n",
    "X_3 = encoded_data[['category', 'userId', 'item']]\n",
    "y = encoded_data['rating']\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y, test_size=0.2, random_state=42)\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Train logistic models\n",
    "logistic_model_1 = LogisticRegression(max_iter=1000)\n",
    "logistic_model_3 = LogisticRegression(max_iter=1000)\n",
    "logistic_model_1.fit(X_1_train, y_1_train)\n",
    "logistic_model_3.fit(X_3_train, y_3_train)\n",
    "\n",
    "\n",
    "#Evaluate models\n",
    "y_1_pred = logistic_model_1.predict(X_1_test)\n",
    "y_3_pred = logistic_model_3.predict(X_3_test)\n",
    "\n",
    "accuracy_1 = accuracy_score(y_1_test, y_1_pred)\n",
    "accuracy_3 = accuracy_score(y_3_test, y_3_pred)\n",
    "print(f'Accuracy of model with 1 feature: {accuracy_1 * 100:.2f}%')\n",
    "print(f'Accuracy of model with 3 feature: {accuracy_3 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca826b90-9f0d-4240-812d-50dd4c08e60c",
   "metadata": {},
   "source": [
    "When using all available features, the model achieved an accuracy of 63.69%. This suggests that the combination of all features collectively contributes to the model's ability to predict the 'rating'.\n",
    "\n",
    "When using only the single most correlated feature, the accuracy increased very slightly to 63.87%. This indicates that this particular feature has a relatively stronger individual influence on the model's predictions compared to the rest. This could imply that this specific feature is highly informative and contributes significantly to the predictive performance.\n",
    "\n",
    "Surprisingly, when incorporating the three most correlated features, the accuracy decreased to 62.57%. This might suggest that the additional features introduced some noise or redundancy into the model, potentially diluting the impact of the most informative feature. It's a common phenomenon in modeling, where adding more features doesn't always lead to better performance, and a subset of highly informative features might be more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50924445-e672-4f5f-a402-86758f16bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Split the dataset and train a KNN model to predict 'rating' based on other features. You can set K with an ad-hoc manner in this step. Evaluate the accuracy of your model.\n",
    "#Although we can resuse the data from the last question, I think it's better to maintain modularity.\n",
    "#Split the dataset on rating\n",
    "X = encoded_data.drop('rating', axis=1)\n",
    "y = encoded_data['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Train the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "#Test the model\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9285f8-0e12-44cf-8a17-c5ba387a59b7",
   "metadata": {},
   "source": [
    "An accuracy score of 60% means that the K-Nearest Neighbors (KNN) model correctly predicted the 'rating' for approximately 60% of the samples in the testing set. In other words, out of all the instances in the testing set, the model made accurate predictions for 60% of them. While this indicates some level of predictive capability, it's important to put this accuracy score into context. Depending on the nature of the problem, a 60% accuracy score may meet intended requirements, however in most cases this would not be sufficient. \n",
    "\n",
    "Similary to the logistic model, let's try using different feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d2624-9f30-4b05-a4bd-c21c6d332168",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = encoded_data[['category']]\n",
    "X_3 = encoded_data[['category', 'userId', 'item']]\n",
    "y = encoded_data['rating']\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(X_1, y, test_size=0.2, random_state=42)\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Train KNN models\n",
    "knn_model_1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model_3 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model_1.fit(X_1_train, y_1_train)\n",
    "knn_model_3.fit(X_3_train, y_3_train)\n",
    "\n",
    "#Evaluate models\n",
    "y_1_pred = knn_model_1.predict(X_1_test)\n",
    "y_3_pred = knn_model_3.predict(X_3_test)\n",
    "\n",
    "accuracy_1 = accuracy_score(y_1_test, y_1_pred)\n",
    "accuracy_3 = accuracy_score(y_3_test, y_3_pred)\n",
    "print(f'Accuracy of model with 1 feature: {accuracy_1 * 100:.2f}%')\n",
    "print(f'Accuracy of model with 3 feature: {accuracy_3 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67376b6f-6541-4296-8099-cf59af155a43",
   "metadata": {},
   "source": [
    "The first KNN model correctly predicted the 'rating' for roughly 60% of the samples in the testing set. It suggests a moderate level of predictive capability, but there may be room for improvement.\n",
    "\n",
    "Surprisingly, when using only the single most correlated feature, the accuracy drops significantly to 46.18%. This indicates that this particular feature, while being highly correlated, might not have enough information on its own to accurately predict the 'rating'. This suggests that the model might be over-relying on this one feature and not effectively utilizing the information from the other features.\n",
    "\n",
    "Interestingly, when incorporating the three most correlated features, the accuracy increases to 62.38%. This suggests that these three features, when combined, provide a more effective set of information for the model to make accurate predictions. This demonstrates the importance of considering multiple potentially informative features in the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003319c5-196c-42c0-be7d-d98e6ceee274",
   "metadata": {},
   "source": [
    "# Comparing the Two Models\n",
    "The logistic regression model and the K-Nearest Neighbors (KNN) model both exhibit distinct strengths and weaknesses in predicting the 'rating' based on different feature sets. The logistic regression model, when considering all features, achieved an accuracy of 63.69%, outperforming the KNN model with all features which achieved an accuracy of 59.78%. This suggests that, for this specific dataset and problem, logistic regression may be better suited to capture the underlying relationships between features and the target variable. However, the KNN model demonstrated a notable improvement when using only the three most correlated features, achieving an accuracy of 62.38%. This indicates that KNN might be more sensitive to a select set of highly informative features. Ultimately, the choice between the models should be driven by the specific characteristics of the dataset and the nature of the problem at hand. Experimentation with different algorithms and feature sets, along with consideration of computational efficiency and interpretability, is crucial in selecting the most effective predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf246e0b-7887-4244-be1c-0119eb63b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Tune the hyper-parameter K in KNN to see how it influences the prediction performance\n",
    "#I will tune knn_model_3 as it had the highest accuracy.\n",
    "\n",
    "# Range of K values to test\n",
    "k_values = list(range(1, 101))\n",
    "\n",
    "# Create a dictionary of hyperparameters and their corresponding values\n",
    "param_grid = {'n_neighbors': k_values}\n",
    "\n",
    "# Initialize GridSearchCV to perform hyperparameter tuning\n",
    "grid_search = GridSearchCV(knn_model_3, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model using GridSearchCV\n",
    "grid_search.fit(X_3_train, y_3_train)\n",
    "\n",
    "# Get the best hyperparameter\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "# Train the model using the best K\n",
    "knn_model_3 = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model_3.fit(X_3_train, y_3_train)\n",
    "\n",
    "# Evaluate the model with the best K\n",
    "y_pred_3 = knn_model_3.predict(X_3_test)\n",
    "accuracy_3 = accuracy_score(y_3_test, y_pred_3)\n",
    "\n",
    "print(f'The best K found is: {best_k}')\n",
    "print(f'Accuracy with the best K: {accuracy_3 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda0685-4392-4125-83be-557a0b420608",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [params['n_neighbors'] for params in grid_search.cv_results_['params']]\n",
    "mean_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(k_values, mean_test_scores, color='skyblue')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Grid Search Results')\n",
    "show_ticks = [1] + list(range(5, len(k_values), 5)) + [100]\n",
    "plt.xticks(show_ticks)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Highlight the best K\n",
    "plt.axvline(x=best_k, color='red', linestyle='--')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced89bb-df41-4abd-9853-b76ad0ff90d9",
   "metadata": {},
   "source": [
    "The model predicted that the optimal number of neighbors is 67, resulting in 63.31% accuracy, an increase of 1.87pp. Although it is an improvement, it is almost negligible.\n",
    "\n",
    "Picking a larger K means the model is less exposed to noise. However, looking at the bar chart of the results, we see that changing K didn't result in much of a change. While there were noticable improvements in the beginning, they eventually smooth out at K = 20."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
